# 1 数据准备
在本项目中，我们选择使用了如下数据集：\
**描述**：THUCTC(THU Chinese Text Classification)是由清华大学自然语言处理实验室推出的中文文本分类工具包，能够自动高效地实现用户自定义的文本分类语料的训练、评测、分类功能。文本分类通常包括特征选取、特征降维、分类模型学习三个步骤。如何选取合适的文本特征并进行降维，是中文文本分类的挑战性问题。我组根据多年在中文文本分类的研究经验，在THUCTC中选取二字串bigram作为特征单元，特征降维方法为Chi-square，权重计算方法为tfidf，分类模型使用的是LibSVM或LibLinear。THUCTC对于开放领域的长文本具有良好的普适性，不依赖于任何中文分词工具的性能，具有准确率高、测试速度快的优点。\
**地址**：http://thuctc.thunlp.org/ \
当然，我更建议下载经过我初步处理后的数据集（谷歌云盘）：
https://drive.google.com/file/d/1cyi6_gUqE30sKn_aoZeto8YTZ17bP2ea/view?usp=sharing\
将其解压后放入`data`目录下即可

## 1.1 数据格式处理

下载后的数据是一个一个的txt文件，每个txt文件中包含一个新闻报道。这样的数据我们是无法直接使用的，所以我们现将数据处理为一个`csv`文件。

```python
import os
import pandas as pd

data_dir = 'THUCNews/data'
output_file = 'data.csv'

data = []

for filename in os.listdir(data_dir):
    if filename.endswith('.txt'):
        file_path = os.path.join(data_dir, filename)

        file_id = int(filename.split('.')[0]) 

        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read().strip()

        data.append({'id': file_id, 'content': content})

df = pd.DataFrame(data)

df = df.sort_values(by='id').reset_index(drop=True)

df.to_csv(output_file, index=False, encoding='utf-8')

print(f"{output_file} have created!")
```

该代码将会从指定的目录`data_dir`中读取所有以`.txt`为后缀的文件，提取这些文件的内容及其对应的`ID`，然后将这些信息整理成一个`Pandas DataFrame`，最后将这个`DataFrame`排序并保存为一个`CSV`文件。


